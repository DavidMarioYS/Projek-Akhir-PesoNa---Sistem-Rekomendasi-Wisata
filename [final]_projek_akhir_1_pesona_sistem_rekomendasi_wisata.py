# -*- coding: utf-8 -*-
"""[FINAL] Projek Akhir 1 : PesoNa - Sistem Rekomendasi Wisata.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GXKiyZxb7OcJIvjPV_FsX8_zJPB3HE9G

**SISTEM REKOMENDASI DESTINASI WISATA PESONA**

---
username : `davidmarioys`

# Data Wrangling
  1. Gathering Data = Mengidentifikasi libraries dan Membaca dataset
  2. Assessing Data = Memeriksa dan memahami data
  3. Cleaning Data = Membersihkan data dari kesalahan/error

## Gathering Data
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import files

from sklearn.preprocessing import LabelEncoder
from geopy.distance import geodesic

import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.preprocessing import MinMaxScaler

# Mengunggah file dari komputer lokal
uploaded = files.upload()

# Load Dataset
df = pd.read_csv('./PesoNa.csv')

print(f'Dataset PesoNa: {df}')

df.info()

df.describe()

"""## Assessing Data"""

print('IDENTIFIKASI DATA')
print(f'\nData Kosong: {df.isnull().sum().sum()}')
print(f'Data Duplikat: {df.duplicated().sum()}')
print(f'\nJumlah Data: {df.shape[0]}')
print(f'Jumlah Kolom: {df.shape[1]}')
print(f'Kolom: {df.columns.tolist()}')
print(f'Tipe Data: {df.dtypes.tolist()}')
print(f'\nNilai Terkecil: \n{df.min()}')
print(f'\nNilai Terbesar: \n{df.max()}')
print(f'\nJumlah Nilai Unique: \n{df.nunique()}')

print('VISUALISASI DATA\n')

# Subplot untuk Rating
plt.subplot(2, 2, 1)
sns.histplot(df['Rating'], kde=True, color='skyblue', bins=15)
plt.title('Distribusi Rating', fontsize=15)
plt.xlabel('Rating', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.grid(axis='y')

# Subplot untuk Reviews
plt.subplot(2, 2, 2)
sns.histplot(df['Reviews'], kde=True, color='salmon', bins=20)
plt.title('Distribusi Reviews', fontsize=15)
plt.xlabel('Reviews', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.grid(axis='y')

# Subplot untuk Latitude
plt.subplot(2, 2, 3)
sns.histplot(df['Latitude'], kde=True, color='green', bins=20)
plt.title('Distribusi Latitude', fontsize=15)
plt.xlabel('Latitude', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.grid(axis='y')

# Subplot untuk Longitude
plt.subplot(2, 2, 4)
sns.histplot(df['Longitude'], kde=True, color='orange', bins=20)
plt.title('Distribusi Longitude', fontsize=15)
plt.xlabel('Longitude', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.grid(axis='y')

plt.tight_layout()
plt.show()

# Filter kolom numerik
numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns

# Hitung korelasi
correlation_matrix = df[numeric_columns].corr()

print("Matrix Korelasi Antar Variabel Numerik:")
print(correlation_matrix)

# Heatmap korelasi
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Heatmap Korelasi Antar Variabel')
plt.show()

"""## Cleaning Data"""

# Drop rows with missing values
df.dropna(inplace=True)

# Check for missing values after dropping rows
print(df.isnull().sum())

# Ubah kolom Reviews menjadi tipe float64
df['Reviews'] = pd.to_numeric(df['Reviews'], errors='coerce')
# Cek tipe data setelah perubahan
print(df.dtypes)

# Convert potentially problematic columns to numeric types
df['Reviews'] = pd.to_numeric(df['Reviews'], errors='coerce')

print('Identifikasi Data Outlier')
numeric_columns = ['Reviews']
Q1 = df[numeric_columns].quantile(0.25)
Q3 = df[numeric_columns].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

outlier_columns = ((df[numeric_columns] < lower_bound) | (df[numeric_columns] > upper_bound)).any(axis=1)
outliers = df[outlier_columns]

print(f'Jumlah Data Outlier: {outliers.shape[0]}')
print(f'Data Outlier: {outliers}')

# Fungsi untuk menghapus outlier secara berulang
def remove_outliers(df, numeric_columns):
    while True:
        Q1 = df[numeric_columns].quantile(0.25)
        Q3 = df[numeric_columns].quantile(0.75)
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outlier_columns = ((df[numeric_columns] < lower_bound) | (df[numeric_columns] > upper_bound)).any(axis=1)
        outliers = df[outlier_columns]

        if outliers.empty:
            break

        df = df[~outlier_columns]

    return df

# Menghapus outlier secara berulang
df_cleaned = remove_outliers(df, numeric_columns)

print("Data setelah menghapus outlier:")
print(df_cleaned)

print(f'Jumlah Data Asli {df.shape}')
print(f'Jumlah Data Setelah Hapus Outlier {df_cleaned.shape}')

df_cleaned

# Filter kolom numerik
numeric_columns = df_cleaned.select_dtypes(include=['float64', 'int64']).columns

# Hitung korelasi
correlation_matrix = df_cleaned[numeric_columns].corr()

print("Matrix Korelasi Antar Variabel Numerik:")
print(correlation_matrix)

# Heatmap korelasi
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Heatmap Korelasi Antar Variabel')
plt.show()

"""## Exploratory Data Analysis (EDA) || Data Preprocessing"""

print('VISUALISASI DATA\n')

# Subplot untuk Rating
plt.subplot(2, 2, 1)
sns.histplot(df_cleaned['Rating'], kde=True, color='skyblue', bins=15)
plt.title('Distribusi Rating', fontsize=15)
plt.xlabel('Rating', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.grid(axis='y')

# Subplot untuk Reviews
plt.subplot(2, 2, 2)
sns.histplot(df_cleaned['Reviews'], kde=True, color='salmon', bins=20)
plt.title('Distribusi Reviews', fontsize=15)
plt.xlabel('Reviews', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.grid(axis='y')

# Subplot untuk Latitude
plt.subplot(2, 2, 3)
sns.histplot(df_cleaned['Latitude'], kde=True, color='green', bins=20)
plt.title('Distribusi Latitude', fontsize=15)
plt.xlabel('Latitude', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.grid(axis='y')

# Subplot untuk Longitude
plt.subplot(2, 2, 4)
sns.histplot(df_cleaned['Longitude'], kde=True, color='orange', bins=20)
plt.title('Distribusi Longitude', fontsize=15)
plt.xlabel('Longitude', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.grid(axis='y')

plt.tight_layout()
plt.show()

df_cleaned['Provinsi'].value_counts()

df_cleaned['KabupatenKota'].value_counts()

df_cleaned['JenisWisata'].value_counts()

# Menghitung jumlah data pada kolom 'Rating' berdasarkan jumlah bintang
rating_counts = df_cleaned['Rating'].value_counts().sort_index()

# Menampilkan jumlah data untuk setiap jumlah bintang
print("Jumlah data berdasarkan jumlah bintang pada Rating:")
for rating, count in rating_counts.items():
    print(f"Rating {rating}: {count} data")

# Label Encoding pada Fitur Kategorikal
## Cek nilai unik pada kolom JenisWisata
print("Nilai unik sebelum encoding:")
print(df_cleaned['JenisWisata'].unique())

## Lakukan Label Encoding pada kolom JenisWisata
label_jenis_wisata = LabelEncoder()
df_cleaned['JenisWisata_Encoded'] = label_jenis_wisata.fit_transform(df_cleaned['JenisWisata'])
label_mapping_jenis_wisata = dict(zip(label_jenis_wisata.classes_, label_jenis_wisata.transform(label_jenis_wisata.classes_)))

## Cek nilai unik setelah encoding
print("\nLabel Mapping Jenis Wisata:")
print(label_mapping_jenis_wisata)

from geopy.distance import geodesic
# Menghitung Jarak
current_location = (-8.123528019761865, 115.06461953075772)  # Contoh koordinat pengguna saat ini

# Fungsi untuk menghitung jarak
def calculate_distance(location1, location2):
    return geodesic(location1, location2).kilometers

# Menambahkan kolom jarak ke DataFrame
df_cleaned['Jarak'] = df_cleaned.apply(lambda row: calculate_distance(current_location, (row['Latitude'], row['Longitude'])), axis=1)

df_cleaned.sort_values(by='Jarak', ascending=True).head(10)

df_cleaned['Jarak']

import folium

# Membuat peta sebaran geografis tempat wisata
map_nusa_tenggara = folium.Map(location=[-8.123528019761865, 115.06461953075772], zoom_start=6)
for _, row in df_cleaned.iterrows():
    folium.Marker([row['Latitude'], row['Longitude']], popup=row['NamaWisata']).add_to(map_nusa_tenggara)

map_nusa_tenggara

df_cleaned.info()

# Filter kolom numerik
numeric_columns = df_cleaned.select_dtypes(include=['float64', 'int64']).columns

# Hitung korelasi
correlation_matrix = df_cleaned[numeric_columns].corr()

print("Matrix Korelasi Antar Variabel Numerik:")
print(correlation_matrix)

# Heatmap korelasi
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".3f", linewidths=0.5)
plt.title('Heatmap Korelasi Antar Variabel')
plt.show()

"""## Modeling
  - Split Data
  - Create Model
  - Train Model
  - Using Callbacks
  - Evaluasi
  - Save Model
"""

# Data X dan Y
X = df_cleaned[['Reviews','JenisWisata_Encoded']]
Y = df_cleaned['Rating']

# Bagi data menjadi train dan test set
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

X_train.fillna(X_train.mean(), inplace=True)  # Replace NaNs with mean, or use another imputation strategy
X_test.fillna(X_test.mean(), inplace=True)

print(X_train.shape)
print(X_test.shape)

def create_model():
    model = Sequential([
        Dense(64, activation='relu', input_shape=(X.shape[1],)),
        Dropout(0.2),
        Dense(32, activation='relu'),
        Dense(1, activation='linear')
    ])
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse', 'mae'])
    return model

model = create_model()
model.summary()

# Menggunakan beberapa callbacks
callbacks = [
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.0001)
]

# Train model dengan callbacks
history = model.fit(X_train, Y_train, epochs=1000, batch_size=32, validation_split=0.2, callbacks=callbacks)

# Evaluasi model di atas test set
Y_pred = model.predict(X_test)
mse = mean_squared_error(Y_test, Y_pred)
mae = mean_absolute_error(Y_test, Y_pred)

print(f'Mean Squared Error: {mse},\nMean Absolute Error: {mae}')

# prompt: Kode untuk Menampilkan Plot Train dan Test MAE MSE, dengan tampilan visualisasi yang menarik

# Plot train and test MAE and MSE
plt.figure(figsize=(15, 5))

# Subplot 1: Train MAE
plt.subplot(1, 2, 1)
plt.plot(history.history['mae'], label='Train MAE')
plt.plot(history.history['val_mae'], label='Test MAE')
plt.title('Train and Test Mean Absolute Error (MAE)', fontsize=15)
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('MAE', fontsize=12)
plt.legend()
plt.grid(True)

# Subplot 2: Train MSE
plt.subplot(1, 2, 2)
plt.plot(history.history['mse'], label='Train MSE')
plt.plot(history.history['val_mse'], label='Test MSE')
plt.title('Train and Test Mean Squared Error (MSE)', fontsize=15)
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('MSE', fontsize=12)
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

# Simpan model ke dalam file H5
model.save('tourism_recommendation_model.h5')
print("Model berhasil disimpan sebagai 'tourism_recommendation_model.h5'")

# Testing Model Rekomendasi
# Model yang telah disimpan
model = tf.keras.models.load_model('tourism_recommendation_model.h5')

# Data untuk prediksi
X_new = df_cleaned[['Reviews', 'JenisWisata_Encoded']]

# Lakukan prediksi
Y_pred = model.predict(X_new)

# Tampilkan hasil prediksi dengan informasi tambahan
print("Hasil Prediksi Jarak dan Informasi Tambahan:")
for i, pred in enumerate(Y_pred):
    print(f"Data {i+1}:")
    print(f"   Provinsi: {df_cleaned['Provinsi'].iloc[i]}")
    print(f"   Kabupaten/Kota: {df_cleaned['KabupatenKota'].iloc[i]}")
    print(f"   Nama Wisata: {df_cleaned['NamaWisata'].iloc[i]}")
    print(f"   Rating: {df_cleaned['Rating'].iloc[i]}")
    print(f"   Prediksi Rating: {pred[0]:.1f}")
    print(f"   Jenis Wisata: {df_cleaned['JenisWisata'].iloc[i]}")
    print(f"   Jarak: {df_cleaned['Jarak'].iloc[i]:.2f} km")
    print("")